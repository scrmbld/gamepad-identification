{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "2b38d5b2",
            "metadata": {},
            "source": [
                "# Run the classifier\n",
                "\n",
                "This notebook uses functions from [classifier.py](classifier.py) in order to run the classifier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f4b76c56",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "import classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f666c24b",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "SEQ_LEN=180\n",
                "SPLIT=(0.6, 0.2, 0.2)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "84c36243",
            "metadata": {},
            "source": [
                "## Load data\n",
                "\n",
                "Read data from the directory that contains our preprocessed data. We still have some preprocessing to do though, because the length of input sequences is a variable that we want to be able to fiddle with."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d8d6d934",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "data_path = 'dataset/displacements/'\n",
                "\n",
                "inputs_by_player = classifier.players_inputs(data_path)\n",
                "\n",
                "inputs_by_player['1'].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eadc3fc9",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "inputs_by_player.keys()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "912e5123",
            "metadata": {},
            "source": [
                "## Organize data into sequences and split data into training, validation, and test sets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14fdc2ff",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = classifier.prepare_data(inputs_by_player, SEQ_LEN, SPLIT)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ee23e558",
            "metadata": {},
            "source": [
                "## Create the model\n",
                "\n",
                "Here is the constructor code for the best version of the model that I tested. Some of the variables that I tested are now hardcoded in the current version, and so the code that is actually in [classifier.py](classifier.py) is not guaranteed to be the same.\n",
                "\n",
                "```python\n",
                "def createClassifier(width=3, seq_len=180):\n",
                "    \"\"\"\n",
                "    Returns a classifier model with the given input shape. Default to width of 3, sequence length of 180.\n",
                "    \"\"\"\n",
                "    input_layer = Input(shape=(seq_len, width))\n",
                "    conv1 = Conv1D(filters=32, kernel_size=7, strides=2, activation=ELU())(input_layer)\n",
                "    conv2 = Conv1D(filters=32, kernel_size=3, strides=1, activation=ELU())(input_layer)\n",
                "\n",
                "    catted = Concatenate(axis=1)([conv1, conv2])\n",
                "    elu1 = ELU(32)(catted)\n",
                "    conv3 = Conv1D(filters=32, kernel_size=2, strides=1, activation=ELU())(elu1)\n",
                "    conv4 = Conv1D(filters=32, kernel_size=2, strides=1, activation=ELU())(conv3)\n",
                "    drop1 = Dropout(0.2)(conv4)\n",
                "\n",
                "    gru1 = LSTM(32, return_sequences=True)(drop1)\n",
                "    gru2 = LSTM(32)(gru1)\n",
                "    drop2 = Dropout(0.2)(gru2)\n",
                "\n",
                "    output = Dense(len(players_set), activation='softmax')(drop2)\n",
                "\n",
                "    model = Model(inputs=input_layer, outputs=output)\n",
                "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
                "    return model\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "034a39dd",
            "metadata": {},
            "outputs": [],
            "source": [
                "model = classifier.createClassifier(width=3, seq_len=SEQ_LEN)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7b6e6e62",
            "metadata": {},
            "source": [
                "## Train the model\n",
                "\n",
                "We now fit the model to the data that we prepared earlier. It is also possible to load in weights instead of running this, so if you already have appropriate weights, this step is optionsl"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0364db04",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# You do not need to run this if you already have model weights saved somewhere\n",
                "history = model.fit(\n",
                "    train_x, train_y, epochs=60, verbose=1, batch_size=64, validation_data=(valid_x, valid_y)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "518da708",
            "metadata": {},
            "outputs": [],
            "source": [
                "# OPTIONAL: run something like this instead of training if you have saved weights previously\n",
                "# model.load_weights('models/default')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4b7f1970",
            "metadata": {},
            "source": [
                "## Plot learning curve"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "233d1b5a",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2b3e2ffb",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "plt.plot('val_accuracy', data=history.history)\n",
                "plt.plot('accuracy', data=history.history)\n",
                "plt.ylabel('accuracy')\n",
                "plt.xlabel('epoch')\n",
                "\n",
                "plt.legend()\n",
                "\n",
                "# plt.savefig('results/learning_curve')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "37e37da3",
            "metadata": {},
            "source": [
                "## Example prediction\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f626effe",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "example_df = pd.read_csv('dataset/displacements/0_1_20210718T014445.csv', index_col=None)\n",
                "predict = model(np.array([example_df.iloc[range(SEQ_LEN), :]], dtype=np.float32), training=False)\n",
                "\n",
                "classifier.i_to_p[np.argmax(predict)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa4f7852",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "np.argmax(predict)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3900cb8e",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# FIXME\n",
                "# It would be best to use model store/load rather than checkpoints\n",
                "# https://www.tensorflow.org/guide/keras/serialization_and_saving\n",
                "# model.save_weights('models/test')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "86a6be83",
            "metadata": {},
            "source": [
                "## Test the model\n",
                "\n",
                "Run the model on the test data and record performance metrics, namely, top N accuracy. More detailed testing can be found in [test_model.ipynb](test_model.ipynb)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "15627aca",
            "metadata": {},
            "source": [
                "### Get test outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0af62f8d",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "test_h = []\n",
                "test_h = model.predict(test_x)\n",
                "\n",
                "test_h.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ddb02b90",
            "metadata": {},
            "source": [
                "### Compare test outputs to labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "066cde80",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "ranks = []\n",
                "\n",
                "for i in range(test_h.shape[0]):\n",
                "    rankings = np.argsort(test_h[i])\n",
                "    rank = (len(classifier.players_set)-1) - np.where((rankings == np.argmax(test_y[i])))[0][0]\n",
                "    ranks.append(rank)\n",
                "\n",
                "topn_occurences = []\n",
                "running = 0\n",
                "for i in range(len(classifier.players_set)):\n",
                "    topn_occurences.append(ranks.count(i) + running)\n",
                "    running += ranks.count(i)\n",
                "\n",
                "topn_acc = [t / topn_occurences[-1] for t in topn_occurences]\n",
                "\n",
                "print(topn_acc)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "tensorflow",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
