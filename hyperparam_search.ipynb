{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated testing of different hyperparameters\n",
    "\n",
    "This notebook is for automatically testing different hyperparameters, including sequence length, convolution kernel sizes, stride lengths, and dropout values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_WIDTH = 3\n",
    "SEQ_LEN = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_inputs = classifier.players_inputs()\n",
    "# don't use the test set here, that's cheating\n",
    "(train_x, train_y), (valid_x, valid_y), (_, _) = classifier.prepare_data(players_inputs, SEQ_LEN)\n",
    "\n",
    "num_players = len(players_inputs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model & run tests for one set of hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(seq_len, kern1, kern2, kern3, stride1, stride2, drop):\n",
    "    model = classifier.createClassifier(INPUT_WIDTH, seq_len, kern1, kern2, kern3, stride1, stride2, drop)\n",
    "    \n",
    "    # train\n",
    "    history = model.fit(\n",
    "        train_x, train_y, epochs=60, verbose=1, batch_size=256, validation_data=(valid_x, valid_y)\n",
    "    )\n",
    "\n",
    "    # test\n",
    "    valid_h = model.predict(valid_x)\n",
    "    ranks = []\n",
    "\n",
    "    for i in range(valid_h.shape[0]):\n",
    "        rankings = np.argsort(valid_h[i])\n",
    "        rank = (num_players-1) - np.where((rankings == np.argmax(valid_y[i])))[0][0]\n",
    "        ranks.append(rank)\n",
    "\n",
    "    topn_occurences = []\n",
    "    running = 0\n",
    "    for i in range(num_players):\n",
    "        topn_occurences.append(ranks.count(i) + running)\n",
    "        running += ranks.count(i)\n",
    "\n",
    "    topn_acc = [t / topn_occurences[-1] for t in topn_occurences]\n",
    "    \n",
    "    return history, topn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try every combination of our hyperparameters\n",
    "\n",
    "This section establishes a list of values for every hyperparameter we are testing. For every combination of hyperparameter values, a model is created and trained. The top 1, 2, and 3 accuracy on the validation set are recorded and appended to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k1_totest = [5, 7, 11]\n",
    "k1_totest = [7, 11] # resuming after 5 is already done\n",
    "k2_totest = [3, 5]\n",
    "k3_totest = [2, 3, 4]\n",
    "s1_totest = [2, 3]\n",
    "s2_totest = [1, 2, 3]\n",
    "# d_totest = [0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oh god\n",
    "for k1 in k1_totest:\n",
    "    for k2 in k2_totest:\n",
    "        for k3 in k3_totest:\n",
    "            for s1 in s1_totest:\n",
    "                for s2 in s2_totest:\n",
    "                        print(f'testing {k1},{k2},{k3},{s1},{s2}...')\n",
    "                        history, topn_acc = test_params(120, k1, k2, k3, s1, s2, 0.2)\n",
    "                        \n",
    "                        # save a training/validation accuracy plot\n",
    "                        plt.figure()\n",
    "                        plt.plot('val_accuracy', data=history.history)\n",
    "                        plt.plot('accuracy', data=history.history)\n",
    "                        plt.ylabel('accuracy')\n",
    "                        plt.xlabel('epoch')\n",
    "\n",
    "                        plt.title(f'kerns=({k1},{k2},{k3}), strides=({s1},{s2}), drop={0.2}')\n",
    "                        plt.legend()\n",
    "                        \n",
    "                        int_d = int(d*10)\n",
    "                        plt.savefig(f'search_plots/k{k1}{k2}{k3}_s{s1}{s2}_d{int_d}.png')\n",
    "\n",
    "                        plt.close()\n",
    "\n",
    "                        # write to the output csv\n",
    "                        with open('results.csv', 'a') as res_file:\n",
    "                            new_row = f'\\n{k1},{k2},{k3},{s1},{s2},{0.2},{topn_acc[0]},{topn_acc[1]},{topn_acc[2]}'\n",
    "                            res_file.write(new_row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
